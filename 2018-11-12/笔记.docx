

URL管理器：管理待抓取URL集合和已抓取URL集合
	防止重复抓取、防止循环抓取

实现方式：内存 Python set（个人 小型）
		  Mysql url status（个人 小型）
		  缓存数据库 redis set （大型企业）


网页下载器
Urllib2 python官方基础模块（网上的教程可能是python3之前的代码，我安装的是python3.7）
Requests 第三方包

方法一   --自己测试代码通过
#在3以后用urllib.request代替urllib2
import urllib.request
response = urllib.request.urlopen('http://www.baidu.com')
#200表示获取成功
print(response.getcode())
print(response.read())

方法二 添加data、http header
import urllib.request
request = urllib.request.Request('http://www.baidu.com')
request.add_header('User-Agent','mozilla/5.0')
response = urllib.request.urlopen(request)
print(response.getcode())

方法三 添加特殊情景的处理器（需要用户登录才能访问、代理等）
import urllib.request,http.cookiejar
cj = http.cookiejar.CookieJar()
opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(cj))
urllib.request.install_opener(opener)
response = urllib.request.urlopen("http://www.baidu.com/")
print(response.getcode())


网页解析器：从网页提取有价值数据的工具
正则表达式 字符串形式的模糊匹配
Html.parser 结构化解析
Beautiful Soup 可使用Html.parser或lxml作为它的解析器，功能比较强大 结构化解析
Lxml 结构化解析
结构化解析——DOM树
 

Beautiful Soup语法
Html网页——创建Beautiful Soup对象——搜索节点find_all、find——访问节点名称、属性、文字

 


print('获取所有的链接')
links = soup.find_all('a')
for link in links:
  print(link.name,link['href'],link.get_text())

print('获取指定的链接')
link_node = soup.find('a',href='http://www.hao123.com/abouthao123')
print(link_node.name,link_node['href'],link_node.get_text())

print('正则匹配')
link_node = soup.find('a',href=re.compile(r'abouthao123'))
print(link_node.name,link_node['href'],link_node.get_text())


确定目标——分析目标（URL格式 数据格式 网页编码）——编写代码——执行爬虫
目标：百度百科Python词条相关词条网页——标题和简介
入口页：https://baike.baidu.com/item/Scarborough%20Fair/9424588?fr=aladdin
URL格式：
词条页面URL： https://baike.baidu.com/item/
正则：^/item/
数据格式：
	标题：<dd class="lemmaWgt-lemmaTitle-title"><h1>Python</h1></dd>
	简介：<div class=" lemma-summary" label-module="para"></div>	
页面编码：UTF-8（若目标网站格式变换，修改代码）



目标：雅虎新闻（标题 图片 内容）
入口页：https://www.yahoo.com/news/
URL格式：
	新闻页面URL：https://www.yahoo.com/news/busy-day-campaigning-trump-obama-ahead-key-u-172418624.html
	正则：^/news/
数据格式：
	
标题：
 
<h1 class="Lh(1.15) Fz(40px) Fz(36px)--modalMinWidth Mb(14px) Ff($ff-primary) Lts($lspacing-md) Fw($fweight) Fsm($fsmoothing) Fsmw($fsmoothing) Fsmm($fsmoothing) Wow(bw)" itemprop="headline"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">奥巴马警告恐惧，特朗普在竞选活动中吹捧经济</font></font></h1>
	
图片：
<img alt="" class=" StretchedBox W(100%) H(100%) ie-7_H(a)" itemprop="url" src="https://s.yimg.com/ny/api/res/1.2/V2Y5S_bUzQ2Fbia_zgJhvA--~A/YXBwaWQ9aGlnaGxhbmRlcjtzbT0xO3c9NDUwO2g9Mjc5O2lsPXBsYW5l/http://media.zenfs.com/en_us/News/Reuters/2018-11-02T211043Z_1_LYNXNPEEA11IL_RTROPTP_2_USA-ELECTION-OBAMA.JPG.cf.jpg">

内容：p标签


Fw(b) Fz(20px) Lh(23px) LineClamp(2,46px) Fz(17px)--sm1024 Lh(19px)--sm1024 LineClamp(2,38px)--sm1024 Td(n) C(#0078ff):h C(#959595)

Fw(b) Fz(20px) Lh(23px) LineClamp(2,46px) Fz(17px)--sm1024 Lh(19px)--sm1024 LineClamp(2,38px)--sm1024 Td(n) C(#0078ff):h C(#959595)


fnd和findAll
首先find(),findAll()是当有了bs对象之后，获取标签组或者单个标签的函数。find()找到第一个满足条件的标签就返回，findAll()找到所有满足条件的标签返回。


canvas-atom canvas-text Mb(1.0em) Mb(0)--sm Mt(0.8em)—sm
canvas-atom canvas-text Mb(1.0em) Mb(0)--sm Mt(0.8em)—sm
canvas-atom canvas-text Mb(1.0em) Mb(0)--sm Mt(0.8em)—sm


Trsdu(.42s) Maw(100%)
StretchedBox W(100%) H(100%) ie-7_H(a)
Trsdu(.42s) StretchedBox W(100%) H(100%) ie-7_H(a)
slideshow-image Maw(100%) Mah(100%) M(a) W(a) StretchedBox


Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.
